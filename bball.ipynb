{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## College Basketball Winning Percentage Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this machine learning notebook, we will try to predict the winning percentage of basketball teams based on various statistics about performance (other than, of course, the number of games won and the number of games played)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the dataset for the 2019 season here: 'https://www.kaggle.com/andrewsundberg/college-basketball-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bball_data = pd.read_csv(\"college-basketball-dataset/cbb19.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TEAM</th>\n",
       "      <th>CONF</th>\n",
       "      <th>G</th>\n",
       "      <th>W</th>\n",
       "      <th>ADJOE</th>\n",
       "      <th>ADJDE</th>\n",
       "      <th>BARTHAG</th>\n",
       "      <th>EFG_O</th>\n",
       "      <th>EFG_D</th>\n",
       "      <th>TOR</th>\n",
       "      <th>...</th>\n",
       "      <th>FTR</th>\n",
       "      <th>FTRD</th>\n",
       "      <th>2P_O</th>\n",
       "      <th>2P_D</th>\n",
       "      <th>3P_O</th>\n",
       "      <th>3P_D</th>\n",
       "      <th>ADJ_T</th>\n",
       "      <th>WAB</th>\n",
       "      <th>POSTSEASON</th>\n",
       "      <th>SEED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Gonzaga</td>\n",
       "      <td>WCC</td>\n",
       "      <td>37</td>\n",
       "      <td>33</td>\n",
       "      <td>123.4</td>\n",
       "      <td>89.9</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>59.0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>14.9</td>\n",
       "      <td>...</td>\n",
       "      <td>35.3</td>\n",
       "      <td>25.9</td>\n",
       "      <td>61.4</td>\n",
       "      <td>43.4</td>\n",
       "      <td>36.3</td>\n",
       "      <td>30.4</td>\n",
       "      <td>72.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>E8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>ACC</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "      <td>123.0</td>\n",
       "      <td>89.9</td>\n",
       "      <td>0.9736</td>\n",
       "      <td>55.2</td>\n",
       "      <td>44.7</td>\n",
       "      <td>14.7</td>\n",
       "      <td>...</td>\n",
       "      <td>29.1</td>\n",
       "      <td>26.3</td>\n",
       "      <td>52.5</td>\n",
       "      <td>45.7</td>\n",
       "      <td>39.5</td>\n",
       "      <td>28.9</td>\n",
       "      <td>60.7</td>\n",
       "      <td>11.1</td>\n",
       "      <td>Champions</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Duke</td>\n",
       "      <td>ACC</td>\n",
       "      <td>38</td>\n",
       "      <td>32</td>\n",
       "      <td>118.9</td>\n",
       "      <td>89.2</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>53.6</td>\n",
       "      <td>45.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>...</td>\n",
       "      <td>33.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>30.8</td>\n",
       "      <td>29.9</td>\n",
       "      <td>73.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>E8</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>ACC</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>120.1</td>\n",
       "      <td>91.4</td>\n",
       "      <td>0.9582</td>\n",
       "      <td>52.9</td>\n",
       "      <td>48.9</td>\n",
       "      <td>17.2</td>\n",
       "      <td>...</td>\n",
       "      <td>30.2</td>\n",
       "      <td>28.4</td>\n",
       "      <td>52.1</td>\n",
       "      <td>47.9</td>\n",
       "      <td>36.2</td>\n",
       "      <td>33.5</td>\n",
       "      <td>76.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>S16</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>B10</td>\n",
       "      <td>37</td>\n",
       "      <td>30</td>\n",
       "      <td>114.6</td>\n",
       "      <td>85.6</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>51.6</td>\n",
       "      <td>44.1</td>\n",
       "      <td>13.9</td>\n",
       "      <td>...</td>\n",
       "      <td>27.5</td>\n",
       "      <td>24.1</td>\n",
       "      <td>51.8</td>\n",
       "      <td>44.3</td>\n",
       "      <td>34.2</td>\n",
       "      <td>29.1</td>\n",
       "      <td>65.9</td>\n",
       "      <td>9.2</td>\n",
       "      <td>S16</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>348</td>\n",
       "      <td>Alcorn St.</td>\n",
       "      <td>SWAC</td>\n",
       "      <td>27</td>\n",
       "      <td>10</td>\n",
       "      <td>89.0</td>\n",
       "      <td>112.6</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>45.7</td>\n",
       "      <td>52.7</td>\n",
       "      <td>24.1</td>\n",
       "      <td>...</td>\n",
       "      <td>30.5</td>\n",
       "      <td>36.5</td>\n",
       "      <td>45.0</td>\n",
       "      <td>55.3</td>\n",
       "      <td>31.3</td>\n",
       "      <td>32.1</td>\n",
       "      <td>67.1</td>\n",
       "      <td>-16.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>349</td>\n",
       "      <td>New Hampshire</td>\n",
       "      <td>AE</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>83.7</td>\n",
       "      <td>106.1</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>44.0</td>\n",
       "      <td>51.5</td>\n",
       "      <td>18.4</td>\n",
       "      <td>...</td>\n",
       "      <td>21.9</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.4</td>\n",
       "      <td>52.1</td>\n",
       "      <td>32.6</td>\n",
       "      <td>33.6</td>\n",
       "      <td>67.1</td>\n",
       "      <td>-20.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>Chicago St.</td>\n",
       "      <td>WAC</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>88.5</td>\n",
       "      <td>117.3</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>44.2</td>\n",
       "      <td>57.8</td>\n",
       "      <td>22.5</td>\n",
       "      <td>...</td>\n",
       "      <td>33.1</td>\n",
       "      <td>33.9</td>\n",
       "      <td>43.5</td>\n",
       "      <td>57.9</td>\n",
       "      <td>30.7</td>\n",
       "      <td>38.5</td>\n",
       "      <td>71.9</td>\n",
       "      <td>-20.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>351</td>\n",
       "      <td>Delaware St.</td>\n",
       "      <td>MEAC</td>\n",
       "      <td>29</td>\n",
       "      <td>6</td>\n",
       "      <td>84.3</td>\n",
       "      <td>112.2</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>40.0</td>\n",
       "      <td>52.4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>25.5</td>\n",
       "      <td>39.2</td>\n",
       "      <td>37.7</td>\n",
       "      <td>52.6</td>\n",
       "      <td>29.0</td>\n",
       "      <td>34.7</td>\n",
       "      <td>71.6</td>\n",
       "      <td>-21.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>352</td>\n",
       "      <td>Maryland Eastern Shore</td>\n",
       "      <td>MEAC</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>85.7</td>\n",
       "      <td>114.4</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>43.5</td>\n",
       "      <td>54.4</td>\n",
       "      <td>20.7</td>\n",
       "      <td>...</td>\n",
       "      <td>28.3</td>\n",
       "      <td>36.6</td>\n",
       "      <td>44.5</td>\n",
       "      <td>53.2</td>\n",
       "      <td>27.9</td>\n",
       "      <td>37.3</td>\n",
       "      <td>64.5</td>\n",
       "      <td>-19.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       TEAM  CONF   G   W  ADJOE  ADJDE  BARTHAG  EFG_O  \\\n",
       "0                   Gonzaga   WCC  37  33  123.4   89.9   0.9744   59.0   \n",
       "1                  Virginia   ACC  38  35  123.0   89.9   0.9736   55.2   \n",
       "2                      Duke   ACC  38  32  118.9   89.2   0.9646   53.6   \n",
       "3            North Carolina   ACC  36  29  120.1   91.4   0.9582   52.9   \n",
       "4                  Michigan   B10  37  30  114.6   85.6   0.9665   51.6   \n",
       "..                      ...   ...  ..  ..    ...    ...      ...    ...   \n",
       "348              Alcorn St.  SWAC  27  10   89.0  112.6   0.0628   45.7   \n",
       "349           New Hampshire    AE  27   5   83.7  106.1   0.0613   44.0   \n",
       "350             Chicago St.   WAC  30   3   88.5  117.3   0.0380   44.2   \n",
       "351            Delaware St.  MEAC  29   6   84.3  112.2   0.0358   40.0   \n",
       "352  Maryland Eastern Shore  MEAC  30   7   85.7  114.4   0.0346   43.5   \n",
       "\n",
       "     EFG_D   TOR  ...   FTR  FTRD  2P_O  2P_D  3P_O  3P_D  ADJ_T   WAB  \\\n",
       "0     44.2  14.9  ...  35.3  25.9  61.4  43.4  36.3  30.4   72.0   7.0   \n",
       "1     44.7  14.7  ...  29.1  26.3  52.5  45.7  39.5  28.9   60.7  11.1   \n",
       "2     45.0  17.5  ...  33.2  24.0  58.0  45.0  30.8  29.9   73.6  11.2   \n",
       "3     48.9  17.2  ...  30.2  28.4  52.1  47.9  36.2  33.5   76.0  10.0   \n",
       "4     44.1  13.9  ...  27.5  24.1  51.8  44.3  34.2  29.1   65.9   9.2   \n",
       "..     ...   ...  ...   ...   ...   ...   ...   ...   ...    ...   ...   \n",
       "348   52.7  24.1  ...  30.5  36.5  45.0  55.3  31.3  32.1   67.1 -16.7   \n",
       "349   51.5  18.4  ...  21.9  38.0  39.4  52.1  32.6  33.6   67.1 -20.2   \n",
       "350   57.8  22.5  ...  33.1  33.9  43.5  57.9  30.7  38.5   71.9 -20.9   \n",
       "351   52.4  19.0  ...  25.5  39.2  37.7  52.6  29.0  34.7   71.6 -21.7   \n",
       "352   54.4  20.7  ...  28.3  36.6  44.5  53.2  27.9  37.3   64.5 -19.9   \n",
       "\n",
       "     POSTSEASON  SEED  \n",
       "0            E8   1.0  \n",
       "1     Champions   1.0  \n",
       "2            E8   1.0  \n",
       "3           S16   1.0  \n",
       "4           S16   2.0  \n",
       "..          ...   ...  \n",
       "348         NaN   NaN  \n",
       "349         NaN   NaN  \n",
       "350         NaN   NaN  \n",
       "351         NaN   NaN  \n",
       "352         NaN   NaN  \n",
       "\n",
       "[353 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bball_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a winning percentage category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bball_data[\"winning_percentage\"] = bball_data[\"W\"]/bball_data[\"G\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.891892\n",
       "1      0.921053\n",
       "2      0.842105\n",
       "3      0.805556\n",
       "4      0.810811\n",
       "         ...   \n",
       "348    0.370370\n",
       "349    0.185185\n",
       "350    0.100000\n",
       "351    0.206897\n",
       "352    0.233333\n",
       "Name: winning_percentage, Length: 353, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bball_data[\"winning_percentage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25     0.937500\n",
       "1      0.921053\n",
       "22     0.914286\n",
       "47     0.909091\n",
       "48     0.903226\n",
       "         ...   \n",
       "346    0.156250\n",
       "343    0.142857\n",
       "338    0.133333\n",
       "263    0.129032\n",
       "350    0.100000\n",
       "Name: winning_percentage, Length: 353, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bball_data[\"winning_percentage\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, some lower ranked teams have a very high winning percentage.  The 48th ranked team has over a 90% winning percentage, one of the best in the NCAA!  This is why straight winning percentage isn't the best metric to use for March Madness predicting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a test set and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating categories based on winning percentage\n",
    "#category 1 teams have a winning percentage of 0-0.20, category 2 teams are 0.20-0.30, category 3 teams are 0.30-0.40, etc.\n",
    "\n",
    "bball_data[\"winning_cat\"] = pd.cut(bball_data[\"winning_percentage\"],bins=[0., .20, .30, .40, .50, .60, .70, .80, .90, 1.00],\n",
    "                               labels=[1, 2, 3, 4, 5, 6, 7, 8, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      8\n",
       "1      9\n",
       "2      8\n",
       "3      8\n",
       "4      8\n",
       "      ..\n",
       "348    3\n",
       "349    1\n",
       "350    1\n",
       "351    2\n",
       "352    2\n",
       "Name: winning_cat, Length: 353, dtype: category\n",
       "Categories (9, int64): [1 < 2 < 3 < 4 ... 6 < 7 < 8 < 9]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bball_data[\"winning_cat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into test set and training set using stratified random sampling\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(bball_data, bball_data[\"winning_cat\"]):\n",
    "    strat_train_set = bball_data.loc[train_index]\n",
    "    strat_test_set = bball_data.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.234043\n",
       "4    0.180851\n",
       "6    0.163121\n",
       "3    0.156028\n",
       "7    0.106383\n",
       "2    0.060284\n",
       "8    0.053191\n",
       "1    0.031915\n",
       "9    0.014184\n",
       "Name: winning_cat, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_train_set[\"winning_cat\"].value_counts()/len(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.239437\n",
       "4    0.183099\n",
       "6    0.169014\n",
       "3    0.154930\n",
       "7    0.098592\n",
       "8    0.056338\n",
       "2    0.056338\n",
       "1    0.028169\n",
       "9    0.014085\n",
       "Name: winning_cat, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strat_test_set[\"winning_cat\"].value_counts()/len(strat_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As desired, we have a test dataset and a training dataset with nearly equal proportions of winning percentage categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restore the dataset by removing overall_cat\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"winning_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bball_data = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting the Data and Looking for Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "winning_percentage    1.000000\n",
       "W                     0.977317\n",
       "WAB                   0.860602\n",
       "BARTHAG               0.747883\n",
       "ADJOE                 0.708684\n",
       "EFG_O                 0.592872\n",
       "2P_O                  0.571187\n",
       "G                     0.516157\n",
       "3P_O                  0.372715\n",
       "ORB                   0.316523\n",
       "TORD                  0.220766\n",
       "FTR                   0.136341\n",
       "ADJ_T                -0.043340\n",
       "FTRD                 -0.199056\n",
       "DRB                  -0.297171\n",
       "TOR                  -0.437187\n",
       "SEED                 -0.439704\n",
       "3P_D                 -0.520244\n",
       "2P_D                 -0.542703\n",
       "EFG_D                -0.629310\n",
       "ADJDE                -0.638652\n",
       "Name: winning_percentage, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bball_data.corr()[\"winning_percentage\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose some objective attributes that are highly correlated with winning percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\"ADJOE\", \"EFG_O\", \"2P_O\", \"3P_O\", \"ORB\", \"TORD\", \"FTRD\", \"DRB\", \"3P_D\", \"2P_D\", \"EFG_D\", \"ADJDE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADJOE is the points scored per 100 possessions, EFG_O is the field goal percentage, 2P_O is the two point shot percentage, ORB is the offensive rebound percentage, TORD is the steal rate, FTRD is the free throw rate allowed, DRB is the defensive rebound percentage, 2PD is the percentage of two point shots allowed, EFG_D is the percentage of field goals allowed, and ADJDE is the points allower per 100 possessions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bball_data = strat_train_set.drop(\"winning_percentage\", axis=1)\n",
    "bball_labels = strat_train_set[\"winning_percentage\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline below will scale all the features appropriately and fill in missing values in any data column with the median of that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "bball_data_final = num_pipeline.fit_transform(bball_data[attributes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.39004207,  0.95899066,  1.00384013, ...,  0.15753046,\n",
       "        -0.73887622, -0.33021249],\n",
       "       [ 1.8119792 ,  0.74886217,  0.44768509, ...,  0.9864433 ,\n",
       "         0.23657381, -0.42024142],\n",
       "       [ 0.44749408,  1.02903349,  0.66396761, ...,  0.71013902,\n",
       "         0.96816133,  0.84016359],\n",
       "       ...,\n",
       "       [ 1.19437014,  1.23916198,  2.08525272, ..., -0.70208287,\n",
       "        -0.66920122, -0.78035714],\n",
       "       [-1.20425107, -1.24735848, -1.28257505, ...,  0.37243379,\n",
       "         0.75913633,  1.23028895],\n",
       "       [ 0.28950106,  0.46869085,  0.72576261, ...,  0.34173331,\n",
       "         0.41076132,  0.39001894]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bball_data_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Best Model using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(bball_data_final, bball_labels)\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "tree_reg.fit(bball_data_final, bball_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, bball_data_final, bball_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.15469167 0.15953725 0.17069052 0.13496131 0.13677666 0.11812306\n",
      " 0.12677388 0.13124601 0.16260268 0.12524544]\n",
      "Mean: 0.14206484718907783\n",
      "Standard deviation: 0.017295493160528325\n"
     ]
    }
   ],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "    \n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree Model is typically off by nearly 14%.  Not bad but let's test a few other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.07766965 0.09000036 0.0832739  0.08009102 0.07654271 0.06365736\n",
      " 0.07131574 0.09397711 0.08231685 0.06193465]\n",
      "Mean: 0.07807793524806485\n",
      "Standard deviation: 0.009801818289967863\n"
     ]
    }
   ],
   "source": [
    "lin_scores = cross_val_score(lin_reg, bball_data_final, bball_labels, scoring = \"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, the linear model was off by only 7.8%!  Let's try one last model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest_reg.fit(bball_data_final, bball_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores: [0.08469616 0.10129147 0.11201104 0.1015472  0.10088692 0.07997675\n",
      " 0.10467496 0.10164631 0.09066318 0.06990288]\n",
      "Mean: 0.0947296869240008\n",
      "Standard deviation: 0.012345313736983707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "forest_scores = cross_val_score(forest_reg, bball_data_final, bball_labels,\n",
    "                                scoring=\"neg_mean_squared_error\", cv=10)\n",
    "forest_rmse_scores = np.sqrt(-forest_scores)\n",
    "display_scores(forest_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good but still not quite as good as the linear model, so let's go with the linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will search for the best combination of hyperparameters for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=LinearRegression(copy_X=True, fit_intercept=True,\n",
       "                                        n_jobs=None, normalize=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid=[{'copy_X': [True], 'fit_intercept': [True]},\n",
       "                         {'n_jobs': [None], 'normalize': [False]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'copy_X': [True], 'fit_intercept': [True]},\n",
    "    {'n_jobs': [None], 'normalize': [False]},\n",
    "  ]\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "grid_search = GridSearchCV(lin_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "\n",
    "grid_search.fit(bball_data_final, bball_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'copy_X': True, 'fit_intercept': True}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07908428570561785 {'copy_X': True, 'fit_intercept': True}\n",
      "0.07908428570561785 {'n_jobs': None, 'normalize': False}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know the best model to use with the appropriate hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model with the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"winning_percentage\", axis=1)\n",
    "y_test = strat_test_set[\"winning_percentage\"].copy()\n",
    "\n",
    "X_test_prepared = num_pipeline.fit_transform(X_test[attributes])\n",
    "\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08318810336457823"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07031772, 0.09431828])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "confidence = 0.95\n",
    "squared_errors = (final_predictions - y_test) ** 2\n",
    "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "loc=squared_errors.mean(),\n",
    "scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 95% confidence interval of error on the test dataset is 7%-9.4%.  Not too shabby!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: Some code is used from the book, Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
